{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cómo crear una aplicación Retriever LLM sencilla con LangChain\n",
    "* Aplicación Retriever LLM muy sencilla sobre una fuente de datos de texto.\n",
    "* Las aplicaciones Retriever pueden responder preguntas sobre documentos específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "from langchain._api import LangChainDeprecationWarning\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory, FileChatMessageHistory\n",
    "warnings.simplefilter(\"ignore\", category=LangChainDeprecationWarning)\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Creamos el modelo a utilizar\n",
    "chatModel = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Creamos nuestro formateador de salida\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar base de datos Chroma\n",
    "\n",
    "Vamos a instalar una base de datos vectorial con el comando `poetry add langchain-chroma`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentos\n",
    "* Un documento LangChain está pensado para almacenar texto y metadatos.\n",
    "* Tiene 2 atributos:\n",
    "    * `page_content`\n",
    "    * `metadata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"John F. Kennedy served as the 35th president of the United States from 1961 until his assassination in 1963.\",\n",
    "        metadata={\"source\": \"us-presidents-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Robert F. Kennedy was a key political figure and served as the U.S. Attorney General; he was also assassinated in 1968.\",\n",
    "        metadata={\"source\": \"us-politics-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"The Kennedy family is known for their significant influence in American politics and their extensive philanthropic efforts.\",\n",
    "        metadata={\"source\": \"kennedy-family-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Edward M. Kennedy, often known as Ted Kennedy, was a U.S. Senator who played a major role in American legislation over several decades.\",\n",
    "        metadata={\"source\": \"us-senators-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Jacqueline Kennedy Onassis, wife of John F. Kennedy, was an iconic First Lady known for her style, poise, and dedication to cultural and historical preservation.\",\n",
    "        metadata={\"source\": \"first-lady-doc\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de datos Vectorial vs Retriever\n",
    "\n",
    "Vamos a destrabar la diferencia entre una `Vector Store` y un `Retriever`.\n",
    "\n",
    "#### Vector Store\n",
    "Piense en un `Vector Store` como un espacio de almacenamiento especializado donde la información se guarda en un formato muy específico:\n",
    "- **Almacenamiento de vectores**: un vector store guarda la información como vectores. Estos vectores son representaciones numéricas de texto, lo que facilita que las máquinas comprendan y comparen la información rápidamente.\n",
    "- **Propósito**: el objetivo principal de un vector store es almacenar y recuperar de manera eficiente estos vectores. Cuando necesita encontrar qué tan similares son dos piezas de información, el vector store ayuda comparando rápidamente sus vectores.\n",
    "- **Uso**: son cruciales en sistemas donde necesita realizar búsquedas de similitud en grandes conjuntos de datos. Por ejemplo, encontrar documentos que traten temas similares o identificar consultas de usuarios similares.\n",
    "\n",
    "#### Retrievers\n",
    "Por otro lado, los retrievers se centran más en la búsqueda activa de información:\n",
    "- **Recuperación de información**: un retriever toma una consulta (como una pregunta o un término de búsqueda) y busca en una base de datos para encontrar información relevante.\n",
    "- **Propósito**: El propósito de un retriever es filtrar grandes cantidades de datos y recuperar los documentos o entradas más relevantes que respondan a la consulta.\n",
    "- **Uso**: Los retriever se utilizan en motores de búsqueda, sistemas de preguntas y respuestas y en cualquier lugar donde necesite extraer rápidamente piezas específicas de información de un gran conjunto de datos.\n",
    "\n",
    "### Diferencias clave\n",
    "- **Funcionalidad**: Los vector store se centran en almacenar y recuperar representaciones de datos numéricos, lo que los hace ideales para tareas que implican medir la similitud. Los retrievers, por su parte, están orientados a buscar en texto o datos para encontrar información relevante en función de una consulta.\n",
    "- **Salida**: Los vector store devuelven vectores o puntuaciones en función de medidas de similitud, mientras que los retrievers proporcionan una lista de documentos o entradas de datos que se consideran relevantes para la consulta.\n",
    "- **Función en los sistemas**: Los vector stores a menudo sirven como un componente de backend que respalda la función de los retrievers al proporcionar las representaciones de datos necesarias para la comparación. Los retrievers utilizan estos datos para realizar su función de búsqueda y obtención de información relevante.\n",
    "\n",
    "En resumen, tanto los vector stores como los retrievers ayudan a gestionar y utilizar grandes conjuntos de datos, pero lo hacen de diferentes maneras. Los vector stores se centran en el almacenamiento y la recuperación de datos en formato numérico, mientras que los retrievers se centran en recuperar entradas de datos o textos relevantes en función de consultas específicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector stores\n",
    "\n",
    "Podemos utilizar muchos Vector Stores en nuestras aplicaciones LangChain. Aquí utilizaremos un vector stores Chorma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### similarity_search()\n",
    "Imagina que tienes una gran caja llena de varios juguetes y estás buscando juguetes que sean similares a tu coche de juguete favorito. Puedes empezar por sacar juguetes que también sean coches, pero luego limitar la búsqueda para encontrar coches que sean del mismo color o tamaño que tu coche favorito.\n",
    "\n",
    "En términos informáticos, la búsqueda por similitud funciona de forma similar. Implica buscar en una gran cantidad de datos (como todos esos juguetes) para encontrar elementos que sean similares a un elemento específico que te interesa. Puede ser texto, imágenes o cualquier tipo de datos.\n",
    "\n",
    "Cuando utilizas la búsqueda por similitud en una aplicación LangChain, esto es lo que suele pasar:\n",
    "1. **Representación**: convertir palabras u oraciones en formas numéricas (llamadas embeddings).\n",
    "2. **Comparación**: una vez que todo se convierte en números, compara estos números para ver qué tan similares son. Esto es como medir la distancia entre dos puntos.\n",
    "3. **Recuperación**: el retriever ordena estos elementos según su similitud con la consulta (lo que está buscando) y le muestra los resultados más similares.\n",
    "\n",
    "La función similarity_search() devuelve documentos en función de su similitud con una consulta de cadena:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.similarity_search(\"John\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### similarity_search_with_score()\n",
    "Cuando hablamos de `similarity_search_with_score`, estamos viendo un proceso un poco más detallado que simplemente encontrar elementos similares. Aquí se explica cómo puede entenderlo:\n",
    "\n",
    "1. **Entrada y representación**:\n",
    "- Primero, tiene una consulta, que es lo que le interesa para encontrar elementos similares. Esto podría ser un fragmento de texto, como una pregunta o un tema.\n",
    "- El sistema convierte esta consulta y todos los elementos potenciales que podrían ser similares (como documentos o fragmentos de texto) en una forma numérica que representa sus significados. Esto generalmente se hace utilizando modelos que producen embeddings.\n",
    "\n",
    "2. **Puntuación de similitudes**:\n",
    "- Una vez que todo se convierte en estas embeddings numéricas, el sistema calcula la \"distancia\" entre el embedding de su consulta y las embeddings de otros elementos. Las distancias más cercanas significan que son más similares.\n",
    "- El sistema utiliza una puntuación de similitud para cuantificar qué tan cerca o lejos está cada elemento de tu consulta. Esta puntuación suele estar entre 0 y 1, donde 1 significa extremadamente similar y 0 significa nada similar.\n",
    "\n",
    "3. **Clasificación y recuperación**:\n",
    "- En función de estas puntuaciones, el sistema clasifica todos los elementos desde el más similar al menos similar.\n",
    "- A continuación, te presenta una lista de elementos, cada uno con una puntuación de similitud que muestra qué tan cerca está de coincidir con tu consulta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al utilizar herramientas de búsqueda de similitudes como las que se analizan en el curso LangChain, estas herramientas suelen convertir el texto en formas numéricas, o vectores, para medir qué tan similares son entre sí. Sin embargo, la forma en que se almacenan y comparan estos vectores puede diferir según la herramienta o el proveedor que utilices; cada uno puede tener su propio método para puntuar las similitudes.\n",
    "\n",
    "A diferencia de otras herramientas que otorgan una puntuación de similitud en la que un número más alto significa más similitud, Chroma hace lo contrario. Utiliza una métrica de distancia para puntuar. En este caso:\n",
    "- **Una distancia menor significa más similitud**: si la puntuación de distancia es cercana a 0, sugiere que los elementos son muy similares.\n",
    "- **Una distancia mayor significa menos similitud**: si la puntuación de distancia es mayor, sugiere que los elementos son bastante diferentes.\n",
    "\n",
    "Por lo tanto, en términos simples, cuando uses el vector store de Chroma para la búsqueda de similitudes, recuerda que estás buscando números (o distancias) más pequeños para encontrar más elementos similares, ya que estas puntuaciones varían inversamente con la similitud: ¡cuanto más pequeño, mejor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.similarity_search_with_score(\"John\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Podemos crear un retriever manualmente, pero esta no es la opción que utilizaremos con más frecuencia. Una vez que elijamos qué método deseamos utilizar para recuperar documentos, podemos crear un retriever utilizando RunnableLambda. El código siguiente creará un retriever en torno al método similarity_search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "retriever = RunnableLambda(vectorstore.similarity_search).bind(k=1)  # select top result\n",
    "\n",
    "retriever.batch([\"John\", \"Robert\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La mayoría de las veces usaremos la función .as_retriever() para crear un Retriever usando el almacén vectorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 1},\n",
    ")\n",
    "\n",
    "retriever.batch([\"John\", \"Robert\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Los Retrievers son ejecutables\n",
    "Los objetos LangChain VectorStore no son Runnables y, por lo tanto, no se pueden integrar de inmediato en LCEL. Por el contrario, los retrievers de LangChain si son ejecutables.\n",
    "* Vea cómo usamos un retriever dentro de una cadena LCEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "message = \"\"\"\n",
    "Responde esta pregunta, usando el contexto indicado.\n",
    "\n",
    "{question}\n",
    "\n",
    "Contexto:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])\n",
    "\n",
    "chain = {\n",
    "    \"context\": retriever,\n",
    "    \"question\": RunnablePassthrough()} | prompt | chatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(\"Háblame sobre Jackie\")\n",
    "\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-demos-9seDwfcA-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
