{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinación de cadenas LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coerción: una cadena dentro de otra cadena\n",
    "* Recuerde: casi cualquier componente de LangChain (prompts, modelos, output parsers, etc.) se puede utilizar como un ejecutable.\n",
    "* **Los Runnables se pueden encadenar entre sí mediante el operador de barra vertical `|`. Las cadenas de ejecutables resultantes también son ejecutables en sí mismas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Dime una frase sobre {politician}\")\n",
    "\n",
    "\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Percy Tejada es un destacado personaje que ha dejado huella en su comunidad a través de su compromiso y dedicación.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Percy Tejada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coerción: combina una cadena con otros Runnables para crear una nueva cadena.\n",
    "* Observa cómo en la `composed_chain` estamos incluyendo la `chain` anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "historian_prompt = ChatPromptTemplate.from_template(\"Fue el {politician} positivo para la Humanidad?\")\n",
    "composed_chain = {\"politician\": chain} | historian_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sí, el liderazgo de Abraham Lincoln es generalmente considerado como un aspecto positivo para la humanidad. Su papel en la abolición de la esclavitud y en la promoción de la igualdad contribuyó significativamente a avanzar en los derechos humanos y en la justicia social. La Emancipación de los esclavos y su firme postura contra la división del país durante la Guerra Civil estadounidense ayudaron a sentar las bases para un futuro en el que los derechos de las personas, independientemente de su raza, fueran reconocidos y protegidos.\\n\\nLincoln defendió ideales de libertad y unidad, y su legado ha influido en movimientos por los derechos civiles y la igualdad en todo el mundo. Sin embargo, también es importante reconocer que su presidencia fue compleja y que sus decisiones a veces generaron críticas. Aun así, en términos generales, su impacto se considera positivo en la lucha por la justicia y la igualdad.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed_chain.invoke({\"politician\": \"Lincoln\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otro ejemplo: una cadena dentro de otra cadena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'François Mitterrand était un homme politique français, donc il est de France, qui est un pays situé en Europe.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"¿De qué país es {politician}?\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"¿De qué continente es el país {country}? responde en {language}\"\n",
    ")\n",
    "\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "\n",
    "chain2 = (\n",
    "    {\"country\": chain1, \"language\": itemgetter(\"language\")}\n",
    "    | prompt2\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain2.invoke({\"politician\": \"Miterrand\", \"language\": \"French\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fallback para cadenas\n",
    "* Al trabajar con modelos de lenguaje, es posible que a menudo encuentre problemas con las API subyacentes, ya sea por limitación de velocidad o tiempo de inactividad. Por lo tanto, a medida que avanza para trasladar sus aplicaciones LLM a producción, se vuelve cada vez más importante protegerse contra estos problemas. Es por eso que LangChain introdujo el concepto de fallbacks.\n",
    "* Un fallback es un plan alternativo que se puede utilizar en caso de emergencia.\n",
    "* Los fallbacks se pueden aplicar no solo en el nivel LLM sino en todo el nivel ejecutable. Esto es importante porque muchas veces los diferentes modelos requieren diferentes indicaciones. Por lo tanto, si su llamada a OpenAI falla, no solo querrá enviar la misma indicación a Anthropic, probablemente desee usar una plantilla de indicación diferente y enviar una versión diferente allí.\n",
    "* Podemos crear fallbacks para cadenas LCEL. Aquí lo hacemos con dos modelos diferentes: ChatOpenAI (con un nombre de modelo incorrecto para crear fácilmente una cadena que genere un error) y luego OpenAI normal (que no usa un modelo de chat). Dado que OpenAI NO es un modelo de chat, es probable que desees un mensaje diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, creemos una cadena con un ChatModel\n",
    "# Agregamos aquí un analizador de salida de cadena para que las salidas entre los dos sean del mismo tipo.\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Eres un asistente divertido que siempre incluye un chiste en su respuesta.\",\n",
    "        ),\n",
    "        (\"human\", \"¿Quién es el mejor jugador mundial en {sport}?\"),\n",
    "    ]\n",
    ")\n",
    "# Aquí vamos a utilizar un nombre de modelo incorrecto para crear fácilmente una cadena que generará un error.\n",
    "chat_model = ChatOpenAI(model=\"gpt-fake\")\n",
    "\n",
    "bad_chain = chat_prompt | chat_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Instrucciones: Eres un asistente divertido que siempre incluye un chiste en su respuesta.\n",
    "\n",
    "Pregunta: ¿Quién es el mejor jugador en {sport}?\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "good_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRespuesta: ¡El árbitro, porque siempre marca goles!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora podemos crear una cadena final que combine los dos\n",
    "chain = bad_chain.with_fallbacks([good_chain])\n",
    "\n",
    "chain.invoke({\"sport\": \"soccer\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-demos-9seDwfcA-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
