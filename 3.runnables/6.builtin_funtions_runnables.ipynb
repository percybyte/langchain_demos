{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principales funciones LCEL integradas para ejecutables\n",
    "\n",
    "En LangChain, las funciones `.bind()` y `.assign()` son utilizadas para configurar y personalizar la ejecución de componentes:\n",
    "\n",
    "- **.bind()**: permite asociar funciones o métodos a un objeto, permitiendo la integración de parámetros y configuraciones específicas para su ejecución.\n",
    "\n",
    "- **.assign()**: se usa para asignar valores a los parámetros de entrada de un runnable, permitiendo la creación de flujos de trabajo más flexibles y personalizados.\n",
    "\n",
    "Ambas funciones facilitan la construcción de cadenas de ejecución más complejas y adaptadas a las necesidades del usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kevin De Bruyne, el talentoso mediocampista belga del Manchester City, es conocido no solo por su habilidad en el campo, sino también por su impresionante visión de juego y precisión en los pases. Un dato curioso sobre él es que, a pesar de su éxito en el fútbol, tuvo un inicio complicado en su carrera. Fue rechazado por el Chelsea en 2012, y en lugar de rendirse, se trasladó a Alemania para jugar en el Werder Bremen. Su actuación allí llamó la atención del VfL Wolfsburg, donde realmente comenzó a destacar y a desarrollar su potencial, lo que finalmente lo llevó de regreso a la Premier League, donde se ha convertido en uno de los mejores mediocampistas del mundo. Este camino muestra su determinación y capacidad para superar obstáculos en su carrera.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Dime algo curioso sobre {soccer_player}\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"soccer_player\": \"De Bruyne\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de .bind() para agregar argumentos a un Runnable en una cadena LCEL\n",
    "* Por ejemplo, podemos agregar un argumento para detener la respuesta del modelo cuando llega a la palabra \"De Bruyne\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kevin De Bruyne, el talentoso mediocampista belga, es conocido no solo por su habilidad en el campo, sino también por su impresionante visión de juego. Un dato curioso sobre él es que, antes de convertirse en una estrella en el Manchester '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model.bind(stop=[\"City\"]) | output_parser\n",
    "\n",
    "chain.invoke({\"soccer_player\": \"De Bruyne\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de .bind() para llamar a una función OpenAI en una cadena LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"soccerfacts\",\n",
    "      \"description\": \"Curious facts about a soccer player\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"question\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The question for the curious facts about a soccer player\"\n",
    "          },\n",
    "          \"answer\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The answer to the question\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"question\", \"answer\"]\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "chain = (\n",
    "    prompt\n",
    "    | model.bind(function_call={\"name\": \"soccerfacts\"}, functions= functions)\n",
    "    | JsonOutputFunctionsParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '¿Qué edad tenía Mbappé cuando debutó en la Ligue 1?',\n",
       " 'answer': 'Mbappé debutó en la Ligue 1 a los 16 años.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input={\"soccer_player\": \"Mbappe\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** La API de OpenAI ha dejado de lado algunas funciones en favor de herramientas. Consulta [aquí](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/openai_functions_agent/) para obtener más información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de .bind() para adjuntar herramientas OpenAI\n",
    "**Nota:** En la API de chat de OpenAI, las funciones ahora se consideran opciones heredadas que se han dejado de lado en favor de las herramientas. Si está creando agentes con modelos LLM de OpenAI, debería usar herramientas de OpenAI en lugar de funciones de OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien generalmente debe utilizar el método .bind_tools() para los modelos que invocan herramientas, también puede vincular argumentos específicos del proveedor directamente si desea un control de nivel inferior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_gyqYtONTE9k5NlKUPpun9G3y', 'function': {'arguments': '{\"location\": \"San Francisco\"}', 'name': 'get_current_weather'}, 'type': 'function'}, {'id': 'call_wtlShy8mpf0yZMzoruYmyvbO', 'function': {'arguments': '{\"location\": \"New York\"}', 'name': 'get_current_weather'}, 'type': 'function'}, {'id': 'call_WSl8Mihw9KN3I74r5kVn6UIH', 'function': {'arguments': '{\"location\": \"Los Angeles\"}', 'name': 'get_current_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 93, 'total_tokens': 156, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d454128e-5f60-4685-a07a-3f5097f3cbbb-0', tool_calls=[{'name': 'get_current_weather', 'args': {'location': 'San Francisco'}, 'id': 'call_gyqYtONTE9k5NlKUPpun9G3y', 'type': 'tool_call'}, {'name': 'get_current_weather', 'args': {'location': 'New York'}, 'id': 'call_wtlShy8mpf0yZMzoruYmyvbO', 'type': 'tool_call'}, {'name': 'get_current_weather', 'args': {'location': 'Los Angeles'}, 'id': 'call_WSl8Mihw9KN3I74r5kVn6UIH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 93, 'output_tokens': 63, 'total_tokens': 156, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\").bind(tools=tools)\n",
    "model.invoke(\"¿Cómo es el clima en San Francisco, Nueva York y Los Ángeles?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La función assign() permite agregar claves a una cadena\n",
    "* Ejemplo: crearemos una clave llamada \"operation_b\" asignada a una función personalizada con un RunnableLambda.\n",
    "* Comenzaremos con una cadena muy básica con solo RunnablePassthrough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "\n",
    "chain = RunnableParallel({\"original_input\": RunnablePassthrough()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_input': 'clima'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"clima\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Como puede ver, en este momento esta cadena solo asigna la entrada del usuario a la variable \"original_input\".\n",
    "* Ahora agreguemos la nueva clave \"uppercase\" con la función de asignación.\n",
    "* En la nueva clave \"uppercase\", usaremos un RunnableLambda con la función personalizada denominada `make_uppercase`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_uppercase(arg):\n",
    "    return arg[\"original_input\"].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({\"original_input\": RunnablePassthrough()}).assign(uppercase=RunnableLambda(make_uppercase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_input': 'clima', 'uppercase': 'CLIMA'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"clima\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Como puede ver, la salida de la cadena ahora tiene 2 claves: original_input y uppercase.\n",
    "* En la clave uppercase, podemos ver que la función `make_uppercase` se ha aplicado a la entrada del usuario."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-demos-9seDwfcA-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
